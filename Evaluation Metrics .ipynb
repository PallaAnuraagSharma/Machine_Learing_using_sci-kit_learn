{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressive Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAE  (Mean Absolute Error)\n",
    "- MSE  (Mean Squared Error)\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- R2   (R squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculated using the difference between the predicted outcomes and the observed outcomes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code -\n",
    "\n",
    "- from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "- from math import sqrt \n",
    "\n",
    "- mae  = mean_absolute_error(x_test,y_predict)\n",
    "- mse  = mean_squared_error(x_test,y_predict)\n",
    "- rmse = sqrt(mse)\n",
    "- r2   = r2_score(x_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy Score \n",
    "* Classification Report \n",
    "* Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Zero Model (ZM) is used to check if the dataset is imbalanced "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code \n",
    "\n",
    "* from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "* import seaborn as sns\n",
    "* score = accuracy_score(x_test,y_pred)\n",
    "* matrix = confusion_matrix(x_test,y_pred)\n",
    "* report = classification_report(x_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ROC - Reciever Operating Characteristics \n",
    "* The ROC curve gives the ratio of false positive rate and true positive rate \n",
    "* AUC - Area Under Curve\n",
    "* AUC for a perfect model is 1 (all the predictions are true positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot ROC: \n",
    "\n",
    "* Classifiers that have decision_function():\n",
    "* Logistic Regression\n",
    "* Support Vector Machine \n",
    "\n",
    "* Classifiers that have predict_proba():\n",
    "* K Nearest Neighbors \n",
    "* Random Forest \n",
    "* Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code - \n",
    "* from sklearn.metrics import roc_curve, auc\n",
    "* rfc = RandomForestClassifier(n_estimators=10, random_state=23)\n",
    "* rfc = rfc.fit(d_train, l_train)\n",
    "* y_score_rfc = rfc.predict_proba(d_test)[:, 1]\n",
    "* fpr_rfc, tpr_rfc, thresholds = roc_curve(l_test, y_score_rfc)\n",
    "* roc_auc_rfc = auc(fpr_rfc, tpr_rfc)\n",
    "* print(f'AUC of Random Forest: {roc_auc_rfc:3.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
