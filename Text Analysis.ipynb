{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dont have many features, just a collection of text\n",
    "* Training cannot be done on text data, therefore we have to process it first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1st step - TOKENIZATION\n",
    "* Stop Words\n",
    "* Stemming\n",
    "* 2nd step - BAG OF WORDS\n",
    "* DTM (Document Term Matrix)\n",
    "* TF-IDF (Term Frequency Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tokenization divides text into individual words\n",
    "* Punctuations are part of some tokens \n",
    "* PYTHON is case sensitive (same word in difference cases is considered as different tokens)\n",
    "* Now we remove all the special characters and unify the tokens with same word and diff case\n",
    "* StopWords - is, that, it, was etc. (they dont have any predictive power)\n",
    "* using NLTK library all the stopwords are removed (Natural Language Tool Kit)\n",
    "* Now some words might be same but be in diff forms (eg. learn,learned,learning)\n",
    "* So all the words are converted to their original forms (STEMMING)\n",
    "* We can apply count on the final list of tokens for analysis\n",
    "* Now we can make a column DTM (Document Term Matrix) - each column is a token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code -\n",
    "* from sklearn.feature_extraction.text import CountVectorizer\n",
    "* cv = CountVectorizer(stop_words = 'english')\n",
    "* cv.fit(training_text)\n",
    "* training_dtm = cv.transform(training_text)\n",
    "* testing_dtm = cv.transform(testing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'Learning', 'is', 'a', 'technique', 'of', 'parsing', 'data,', 'learn', 'from', 'that', 'data', 'and', 'then', 'apply', 'what', 'is', 'learned', 'to', 'make', 'an', 'informed', 'decision.', 'Machine', 'learning', 'focuses', 'on', 'designing', 'algorithms', 'that', 'can', 'learn', 'from', 'and', 'make', 'predictions', 'on', 'the', 'data.', 'The', 'learning', 'can', 'be', 'supervised', 'or', 'unsupervised.']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Machine Learning is a technique of parsing data, learn from that data and then \n",
    "apply what is learned to make an informed decision. Machine learning focuses on \n",
    "designing algorithms that can learn from and make predictions on the data. \n",
    "The learning can be supervised or unsupervised.\n",
    "\"\"\"\n",
    "print(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Words:  Counter({'Machine': 2, 'is': 2, 'learn': 2, 'from': 2, 'that': 2, 'and': 2, 'make': 2, 'learning': 2, 'on': 2, 'can': 2, 'Learning': 1, 'a': 1, 'technique': 1, 'of': 1, 'parsing': 1, 'data,': 1, 'data': 1, 'then': 1, 'apply': 1, 'what': 1, 'learned': 1, 'to': 1, 'an': 1, 'informed': 1, 'decision.': 1, 'focuses': 1, 'designing': 1, 'algorithms': 1, 'predictions': 1, 'the': 1, 'data.': 1, 'The': 1, 'be': 1, 'supervised': 1, 'or': 1, 'unsupervised.': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Machine', 2),\n",
       " ('is', 2),\n",
       " ('learn', 2),\n",
       " ('from', 2),\n",
       " ('that', 2),\n",
       " ('and', 2),\n",
       " ('make', 2),\n",
       " ('learning', 2),\n",
       " ('on', 2),\n",
       " ('can', 2)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections as cl\n",
    "words = text.split()\n",
    "wc = cl.Counter(words)\n",
    "print('No. of Words: ',wc)\n",
    "wc.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning is a technique of parsing data  learn from that data and then  apply what is learned to make an informed decision  Machine learning focuses on  designing algorithms that can learn from and make predictions on the data   The learning can be supervised or unsupervised  '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "text_ns = re.sub(r'[^\\w]',' ', text)\n",
    "text_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning is a technique of parsing data  learn from that data and then  apply what is learned to make an informed decision  machine learning focuses on  designing algorithms that can learn from and make predictions on the data   the learning can be supervised or unsupervised  \n"
     ]
    }
   ],
   "source": [
    "text_nsl = text_ns.lower()\n",
    "print(text_nsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'learning': 3, 'data': 3, 'machine': 2, 'is': 2, 'learn': 2, 'from': 2, 'that': 2, 'and': 2, 'make': 2, 'on': 2, 'can': 2, 'the': 2, 'a': 1, 'technique': 1, 'of': 1, 'parsing': 1, 'then': 1, 'apply': 1, 'what': 1, 'learned': 1, 'to': 1, 'an': 1, 'informed': 1, 'decision': 1, 'focuses': 1, 'designing': 1, 'algorithms': 1, 'predictions': 1, 'be': 1, 'supervised': 1, 'or': 1, 'unsupervised': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('learning', 3),\n",
       " ('data', 3),\n",
       " ('machine', 2),\n",
       " ('is', 2),\n",
       " ('learn', 2),\n",
       " ('from', 2),\n",
       " ('that', 2),\n",
       " ('and', 2),\n",
       " ('make', 2),\n",
       " ('on', 2)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = cl.Counter(text_nsl.split())\n",
    "print(wc)\n",
    "wc.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count:  Counter({'data': 3, 'Machine': 2, 'learn': 2, 'make': 2, 'learning': 2, 'Learning': 1, 'technique': 1, 'parsing': 1, 'apply': 1, 'learned': 1, 'informed': 1, 'decision': 1, 'focuses': 1, 'designing': 1, 'algorithms': 1, 'predictions': 1, 'The': 1, 'supervised': 1, 'unsupervised': 1})\n",
      "Top 10 words: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('learning', 3),\n",
       " ('data', 3),\n",
       " ('machine', 2),\n",
       " ('learn', 2),\n",
       " ('make', 2),\n",
       " ('technique', 1),\n",
       " ('parsing', 1),\n",
       " ('apply', 1),\n",
       " ('learned', 1),\n",
       " ('informed', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text_nsl.split()\n",
    "words_no_stop = []\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        words_no_stop.append(word)\n",
    "wc1 = cl.Counter(words_no_stop)\n",
    "print('Word Count: ',wc)\n",
    "print('Top 10 words: ')\n",
    "wc1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count:  Counter({'learn': 6, 'data': 3, 'machin': 2, 'make': 2, 'techniqu': 1, 'pars': 1, 'appli': 1, 'inform': 1, 'decis': 1, 'focus': 1, 'design': 1, 'algorithm': 1, 'predict': 1, 'supervis': 1, 'unsupervis': 1})\n",
      "Ten Most Common: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('learn', 6),\n",
       " ('data', 3),\n",
       " ('machin', 2),\n",
       " ('make', 2),\n",
       " ('techniqu', 1),\n",
       " ('pars', 1),\n",
       " ('appli', 1),\n",
       " ('inform', 1),\n",
       " ('decis', 1),\n",
       " ('focus', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "\n",
    "words_clean = []\n",
    "for word in words_no_stop:\n",
    "    words_clean.append(st.stem(word))\n",
    "wc = cl.Counter(words_clean)\n",
    "print('Word Count: ', wc)\n",
    "print('Ten Most Common: ')\n",
    "wc.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens:  38\n",
      "Tokens :\n",
      "['additional', 'algorithms', 'apply', 'appropriate', 'behavioral', 'catering', 'children', 'data', 'decision', 'designed', 'designing', 'difficulties', 'disabilities', 'education', 'educational', 'focuses', 'informed', 'learn', 'learned', 'learning', 'machine', 'make', 'needs', 'parsing', 'physical', 'predictions', 'problems', 'provide', 'resourced', 'school', 'schools', 'special', 'specifically', 'staffed', 'students', 'supervised', 'technique', 'unsupervised']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of Training Samples:  2\n",
      "Number of Testing Samples:  2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Testing dtm\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 1]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0\n",
      "  0 0]]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "training_text = [\"\"\"Machine Learning is a technique of parsing data, learn from that data and then \n",
    "        apply what is learned to make an informed decision. Machine learning focuses on \n",
    "        designing algorithms that can learn from and make predictions on the data. \n",
    "        The learning can be supervised or unsupervised.\"\"\",\n",
    "        \"\"\"A special school is a school catering for students who have special educational needs \n",
    "        due to learning difficulties, physical disabilities or behavioral problems. Special \n",
    "        schools may be specifically designed, staffed and resourced to provide appropriate \n",
    "        special education for children with additional needs.\n",
    "        \"\"\"]\n",
    "\n",
    "\n",
    "testing_text = [\"Machine learning has supervised and unsupervised learning.\",\n",
    "               \"Special education is important because children with special needs have equal rights to education.\"]\n",
    "\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(training_text)\n",
    "\n",
    "training_dtm = cv.transform(training_text)\n",
    "testing_dtm = cv.transform(testing_text)\n",
    "\n",
    "\n",
    "print('Number of Tokens: ', training_dtm.shape[1])\n",
    "print('Tokens :')\n",
    "print(cv.get_feature_names())\n",
    "\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "\n",
    "print('Number of Training Samples: ', training_dtm.shape[0])\n",
    "print('Number of Testing Samples: ', testing_dtm.shape[0])\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "print('Testing dtm')\n",
    "print(testing_dtm.todense())\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>apply</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>behavioral</th>\n",
       "      <th>catering</th>\n",
       "      <th>children</th>\n",
       "      <th>data</th>\n",
       "      <th>decision</th>\n",
       "      <th>designed</th>\n",
       "      <th>designing</th>\n",
       "      <th>difficulties</th>\n",
       "      <th>disabilities</th>\n",
       "      <th>education</th>\n",
       "      <th>educational</th>\n",
       "      <th>focuses</th>\n",
       "      <th>informed</th>\n",
       "      <th>learn</th>\n",
       "      <th>learned</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>make</th>\n",
       "      <th>needs</th>\n",
       "      <th>parsing</th>\n",
       "      <th>physical</th>\n",
       "      <th>predictions</th>\n",
       "      <th>problems</th>\n",
       "      <th>provide</th>\n",
       "      <th>resourced</th>\n",
       "      <th>school</th>\n",
       "      <th>schools</th>\n",
       "      <th>special</th>\n",
       "      <th>specifically</th>\n",
       "      <th>staffed</th>\n",
       "      <th>students</th>\n",
       "      <th>supervised</th>\n",
       "      <th>technique</th>\n",
       "      <th>unsupervised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   additional  algorithms  apply  appropriate  behavioral  catering  children  \\\n",
       "0           0           0      0            0           0         0         0   \n",
       "1           0           0      0            0           0         0         1   \n",
       "\n",
       "   data  decision  designed  designing  difficulties  disabilities  education  \\\n",
       "0     0         0         0          0             0             0          0   \n",
       "1     0         0         0          0             0             0          2   \n",
       "\n",
       "   educational  focuses  informed  learn  learned  learning  machine  make  \\\n",
       "0            0        0         0      0        0         2        1     0   \n",
       "1            0        0         0      0        0         0        0     0   \n",
       "\n",
       "   needs  parsing  physical  predictions  problems  provide  resourced  \\\n",
       "0      0        0         0            0         0        0          0   \n",
       "1      1        0         0            0         0        0          0   \n",
       "\n",
       "   school  schools  special  specifically  staffed  students  supervised  \\\n",
       "0       0        0        0             0        0         0           1   \n",
       "1       0        0        2             0        0         0           0   \n",
       "\n",
       "   technique  unsupervised  \n",
       "0          0             1  \n",
       "1          0             0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "training_data = training_dtm.todense().tolist()\n",
    "testing_data  = testing_dtm.todense().tolist()\n",
    "training_df   = pd.DataFrame(training_data,columns=cv.get_feature_names())\n",
    "testing_df    = pd.DataFrame(testing_data,columns=cv.get_feature_names())\n",
    "testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>apply</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>behavioral</th>\n",
       "      <th>catering</th>\n",
       "      <th>children</th>\n",
       "      <th>data</th>\n",
       "      <th>decision</th>\n",
       "      <th>designed</th>\n",
       "      <th>designing</th>\n",
       "      <th>difficulties</th>\n",
       "      <th>disabilities</th>\n",
       "      <th>education</th>\n",
       "      <th>educational</th>\n",
       "      <th>focuses</th>\n",
       "      <th>informed</th>\n",
       "      <th>learn</th>\n",
       "      <th>learned</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>make</th>\n",
       "      <th>needs</th>\n",
       "      <th>parsing</th>\n",
       "      <th>physical</th>\n",
       "      <th>predictions</th>\n",
       "      <th>problems</th>\n",
       "      <th>provide</th>\n",
       "      <th>resourced</th>\n",
       "      <th>school</th>\n",
       "      <th>schools</th>\n",
       "      <th>special</th>\n",
       "      <th>specifically</th>\n",
       "      <th>staffed</th>\n",
       "      <th>students</th>\n",
       "      <th>supervised</th>\n",
       "      <th>technique</th>\n",
       "      <th>unsupervised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489531</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.348306</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.163177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.306763</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.613527</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   additional  algorithms     apply  appropriate  behavioral  catering  \\\n",
       "0    0.000000    0.163177  0.163177     0.000000    0.000000  0.000000   \n",
       "1    0.153382    0.000000  0.000000     0.153382    0.153382  0.153382   \n",
       "\n",
       "   children      data  decision  designed  designing  difficulties  \\\n",
       "0  0.000000  0.489531  0.163177  0.000000   0.163177      0.000000   \n",
       "1  0.153382  0.000000  0.000000  0.153382   0.000000      0.153382   \n",
       "\n",
       "   disabilities  education  educational   focuses  informed     learn  \\\n",
       "0      0.000000   0.000000     0.000000  0.163177  0.163177  0.326354   \n",
       "1      0.153382   0.153382     0.153382  0.000000  0.000000  0.000000   \n",
       "\n",
       "    learned  learning   machine      make     needs   parsing  physical  \\\n",
       "0  0.163177  0.348306  0.326354  0.326354  0.000000  0.163177  0.000000   \n",
       "1  0.000000  0.109132  0.000000  0.000000  0.306763  0.000000  0.153382   \n",
       "\n",
       "   predictions  problems   provide  resourced    school   schools   special  \\\n",
       "0     0.163177  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.153382  0.153382   0.153382  0.306763  0.153382  0.613527   \n",
       "\n",
       "   specifically   staffed  students  supervised  technique  unsupervised  \n",
       "0      0.000000  0.000000  0.000000    0.163177   0.163177      0.163177  \n",
       "1      0.153382  0.153382  0.153382    0.000000   0.000000      0.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_cv = TfidfVectorizer(stop_words='english')\n",
    "training_dtm_tf = tf_cv.fit_transform(training_text)\n",
    "testing_dtm_tf  = tf_cv.transform(testing_text)\n",
    "\n",
    "training_data_tf = training_dtm_tf.todense().tolist()\n",
    "training_tf_df = pd.DataFrame(training_data_tf,columns=cv.get_feature_names())\n",
    "training_tf_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
